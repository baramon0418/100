{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkz6Bt-lVcBm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# MNIST 읽어 와서 신경망에 입력할 형태로 변환\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000,784) # 텐서 모양 변환\n",
        "x_test = x_test.reshape(10000,784)\n",
        "x_train=x_train.astype(np.float32)/255.0 # ndarray로 변환\n",
        "x_test=x_test.astype(np.float32)/255.0 #255로 나눠주는 이유는 웨이트 값을 줄여주기 위해서 \n",
        "y_train=tf.keras.utils.to_categorical(y_train,10) # 원핫 코드로 변환\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "#신경망 구조 설계\n",
        "n_input=784\n",
        "n_hidden1=1024\n",
        "n_hidden2=500\n",
        "n_output=10\n",
        "\n",
        "mlp=Sequential()\n",
        "mlp.add (Dense(units=n_hidden1,activation='tanh',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
        "mlp.add (Dense(units=n_hidden2,activation='tanh',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
        "mlp.add(Dense(units=n_output,activation='tanh',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
        "\n",
        "#신경망 학습\n",
        "mlp.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001),metrics=['accuracy']) #손실 함수로 MSE 사용, 옵티마이저(학습률을 곱해주는 거)로 Adam 사용\n",
        "hist=mlp.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2) #학습 도중에 발생한 정보를 hist 객체에 저장해 둠(시각화에 활용)\n",
        "\n",
        "#학습된 신경망으로 예측\n",
        "res=mlp.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"정확률은\",res[1]*100)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 정확률 곡선\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# 손실 함수 곡선\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper right')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# fashion MNIST 데이터셋을 읽어와 신경망에 입력할 형태로 변환\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(60000,784) # 텐서 모양 변환\n",
        "x_test = x_test.reshape(10000,784)\n",
        "x_train=x_train.astype(np.float32)/255.0 # ndarray로 변환\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10) # 원핫 코드로 변환\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "n_input=784\n",
        "n_hidden=812\n",
        "n_hidden2=512\n",
        "n_hidden3=512\n",
        "n_output=10\n",
        "\n",
        "mlp=Sequential()\n",
        "mlp.add (Dense(units=n_hidden,activation='tanh',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
        "mlp.add (Dense(units=n_hidden2,activation='tanh',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
        "mlp.add (Dense(units=n_hidden3,activation='tanh',input_shape=(n_input,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
        "mlp.add(Dense(units=n_output,activation='tanh',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
        "\n",
        "mlp.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
        "hist=mlp.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n",
        "\n",
        "res=mlp.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"정확률은\",res[1]*100)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 정확률 곡선\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# 손실 함수 곡선\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper right')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3bRsSssiV-k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6-1\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000,28,28,1) # 텐서 모양 변환\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "x_train=x_train.astype(np.float32)/255.0 # ndarray로 변환\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10) # 원핫 코드로 변환\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(6,(5,5),padding='same', activation='relu',input_shape=(28,28,1)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Conv2D(16,(5,5),padding='same', activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Conv2D(120,(5,5),padding='same', activation='relu'))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(84, activation='relu'))\n",
        "cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "hist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n",
        "\n",
        "res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"정확률은\",res[1]*100)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 정확률 곡선\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# 손실 함수 곡선\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VKqiV-0WnNN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6-2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000,28,28,1) # 텐서 모양 변환\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "x_train=x_train.astype(np.float32)/255.0 # ndarray로 변환\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10) # 원핫 코드로 변환\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(128, activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "hist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n",
        "\n",
        "res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"정확률은\",res[1]*100)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 정확률 곡선\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# 손실 함수 곡선\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a3rwk1qKnuUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# MNIST 읽어 와서 신경망에 입력할 형태로 변환\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train=x_train.astype(np.float32)/255.0 # ndarray로 변환\n",
        "x_test=x_test.astype(np.float32)/255.0 #255로 나눠주는 이유는 웨이트 값을 줄여주기 위해서 \n",
        "y_train=tf.keras.utils.to_categorical(y_train,10) # 원핫 코드로 변환\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "batch_siz=128\n",
        "n_epoch=10\n",
        "k=5\n",
        "\n",
        "def cross_validation(data_gen,dropout_rate,l2_reg):\n",
        "    accuracy=[]\n",
        "    for train_index,val_index in KFold(k).split(x_train):\n",
        "        xtrain,xval=x_train[train_index],x_train[val_index]\n",
        "        ytrain,yval=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        # 신경망 모델 설계\n",
        "        cnn=Sequential()\n",
        "        cnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "        cnn.add(Conv2D(32,(3,3),activation='relu'))\n",
        "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        cnn.add(Dropout(dropout_rate[0]))\n",
        "        cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "        cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        cnn.add(Dropout(dropout_rate[1]))\n",
        "        cnn.add(Flatten())\n",
        "        cnn.add(Dense(512,activation='relu'))\n",
        "        cnn.add(Dropout(dropout_rate[2]))\n",
        "        cnn.add(Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(l2_reg)))\n",
        "\n",
        "        # 신경망을 학습하고 정확률 평가\n",
        "        cnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "        if data_gen:\n",
        "            generator=ImageDataGenerator(rotation_range=3.0,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True)\n",
        "            cnn.fit_generator(generator.flow(x_train,y_train,batch_size=batch_siz),epochs=n_epoch,validation_data=(x_test,y_test),verbose=2)\n",
        "        else:\n",
        "            cnn.fit(xtrain,ytrain,batch_size=batch_siz,epochs=n_epoch, validation_data=(x_test,y_test),verbose=2)\n",
        "        accuracy.append(cnn.evaluate(xval,yval,verbose=0)[1])\n",
        "    return accuracy\n",
        "\n",
        "acc_000 = cross_validation(False,[0.0,0.0,0.0],0.0)\n",
        "acc_001 = cross_validation(False,[0.0,0.0,0.0],0.01)\n",
        "acc_010 = cross_validation(False,[0.25,0.25,0.5],0.0)\n",
        "acc_011 = cross_validation(False,[0.25,0.25,0.5],0.01)\n",
        "acc_100 = cross_validation(True,[0.0,0.0,0.0],0.0)\n",
        "acc_101 = cross_validation(True,[0.0,0.0,0.0],0.01)\n",
        "acc_110 = cross_validation(True,[0.25,0.25,0.5],0.0)\n",
        "acc_111 = cross_validation(True,[0.25,0.25,0.5],0.01)\n",
        "\n",
        "print(\"출력 형식: [Data augmentation-Dropout-l2 regularizer] 교차검증 시도/평균\")\n",
        "print(\"[000] (\", acc_000,\"/\",np.array(acc_000).mean(),\")\")\n",
        "print(\"[001] (\", acc_001,\"/\",np.array(acc_001).mean(),\")\")\n",
        "print(\"[010] (\", acc_010,\"/\",np.array(acc_010).mean(),\")\")\n",
        "print(\"[011] (\", acc_011,\"/\",np.array(acc_011).mean(),\")\")\n",
        "print(\"[100] (\", acc_100,\"/\",np.array(acc_100).mean(),\")\")\n",
        "print(\"[101] (\", acc_101,\"/\",np.array(acc_101).mean(),\")\")\n",
        "print(\"[110] (\", acc_110,\"/\",np.array(acc_110).mean(),\")\")\n",
        "print(\"[111] (\", acc_111,\"/\",np.array(acc_111).mean(),\")\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.grid()\n",
        "plt.boxplot([acc_000,acc_001,acc_010,acc_011,acc_100,acc_101,acc_110,acc_111])\n",
        "labels=[\"000\",\"001\", \"010\", \"011\",\"100\",\"101\",\"110\",\"111\"]"
      ],
      "metadata": {
        "id": "ctLe7SH-kFaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "\n",
        "train_folder='CUB200/train'\n",
        "train_folder='CUB200/test'\n",
        "\n",
        "class_reduce=0.1\n",
        "no_class=int(len(os.listdir(train_folder))*class_reduce)\n",
        "\n",
        "x_train,y_train=[],[]\n",
        "for i,class_name in enumerate(os.listdir(train_folder)):\n",
        "  if i<no_class:\n",
        "    for fname in os.listdir(train_folder+'/'+class_name):\n",
        "      img=image.load_img(train_folder+'/'+class_name+'/'+fname,target_size(224,224))\n",
        "      if len(img.getbands())!=3:\n",
        "        print(\"주의: 유효하지 않은 영상 발생\",class_name,fname)\n",
        "        continue\n",
        "      x=image.img_to_array(img)\n",
        "      x=preprocess_input(x)\n",
        "      x_train.append(x)\n",
        "      y_train.append(i)\n",
        "\n",
        "  x_test,y_test=[],[]\n",
        "  for i,class0=_name in enumerate(os.listdir(test_folder)):\n",
        "    if i<no_class:\n",
        "      for fname in os.listdir(test_folder+'/'+class_name):\n",
        "        img=image.load_img(test_folder+'/'+class_name+'/'+fname,target_size=(224,224))\n",
        "        if len(img.getbands())!=3:\n",
        "        print(\"주의: 유효하지 않은 영상 발생\",class_name,fname)\n",
        "        continue\n",
        "      x=image.img_to_array(img)\n",
        "      x=preprocess_input(x)\n",
        "      x_test.append(x)\n",
        "      y_test.append(i)\n",
        "  \n",
        "x_train=np.asarray(x_train)\n",
        "y_train=np.asarray(y_train)\n",
        "x_test=np.asarray(x_test)\n",
        "y_test=np.asarray(y_test)\n",
        "y_train = tf.keras.utils.to_categorical(y_train,no_class)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,np_class)\n",
        "\n",
        "base_model=ResNet50"
      ],
      "metadata": {
        "id": "T_o8zC-8pBxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8-2\n",
        "from tensorflow.python import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=open(\"BTC_USD_2019-02-28_2020-02-27-CoinDesk.csv\",\"r\")\n",
        "coindesk_data = pd.read_csv(f,header=0)\n",
        "seq=coindesk_data[['Closing Price (USD)']].to_numpy()\n",
        "\n",
        "def seq2dataset(seq,window,horizon):\n",
        "    X=[]; Y=[]\n",
        "    for i in range(len(seq)-(window+horizon)+1):\n",
        "        x=seq[i:(i+window)]\n",
        "        y=(seq[i+window+horizon-1])\n",
        "        X.append(x); Y.append(y)\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "w=7\n",
        "h=1\n",
        "\n",
        "X,Y=seq2dataset(seq,w,h)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "split=int(len(X)*0.7)\n",
        "x_train=X[0:split]; y_train=Y[0:split]\n",
        "x_test=X[split:]; y_test=Y[split:]\n",
        "\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=128,activation='relu', input_shape=x_train[0].shape))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae',optimizer='adam',metrics=['mae'])\n",
        "hist=model.fit(x_train, y_train,epochs=200, batch_size=1,validation_data=(x_test,y_test),verbose=2)\n",
        "\n",
        "ev=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"손실함수\", ev[0],\"MAE\", ev[1])\n",
        "\n",
        "pred=model.predict(x_test)\n",
        "print(\"평균절댓값백분율오차(MAPE):\", sum(abs(y_test-pred)/y_test)/len(x_test))\n",
        "\n",
        "plt.plot(hist.history['mae'])\n",
        "plt.plot(hist.history['val_mae'])\n",
        "plt.title('Model mae')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim([120,800])\n",
        "plt.legend(['Train','Validation'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "x_range=range(len(y_test))\n",
        "plt.plot(x_range,y_test[x_range],color='red')\n",
        "plt.plot(x_range,pred[x_range],color='blue')\n",
        "plt.legend(['True prices','Predicted prices'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "x_range=range(50,64)\n",
        "plt.plot(x_range,y_test[x_range],color='red')\n",
        "plt.plot(x_range,pred[x_range],color='blue')\n",
        "plt.legend(['True prices','Predicted prices'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lcbuXx_Kp9vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8-3\n",
        "from tensorflow.python import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=open(\"BTC_USD_2019-02-28_2020-02-27-CoinDesk.csv\",\"r\")\n",
        "coindesk_data = pd.read_csv(f,header=0)\n",
        "seq=coindesk_data[['Closing Price (USD)','24h Open (USD)', '24h High (USD)', '24h Low (USD)']].to_numpy()\n",
        "\n",
        "def seq2dataset(seq,window,horizon):\n",
        "    X=[]; Y=[]\n",
        "    for i in range(len(seq)-(window+horizon)+1):\n",
        "        x=seq[i:(i+window)]\n",
        "        y=(seq[i+window+horizon-1])\n",
        "        X.append(x); Y.append(y)\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "w=7\n",
        "h=1\n",
        "\n",
        "X,Y=seq2dataset(seq,w,h)\n",
        "print(X.shape,Y.shape)\n",
        "print(X[0],Y[0])\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "split=int(len(X)*0.7)\n",
        "x_train=X[0:split]; y_train=Y[0:split]\n",
        "x_test=X[split:]; y_test=Y[split:]\n",
        "\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=128,activation='relu', input_shape=x_train[0].shape))\n",
        "model.add(Dense(4))\n",
        "model.compile(loss='mae',optimizer='adam',metrics=['mae'])\n",
        "hist=model.fit(x_train, y_train,epochs=200, batch_size=1,validation_data=(x_test,y_test),verbose=2)\n",
        "\n",
        "ev=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"손실함수\", ev[0],\"MAE\", ev[1])\n",
        "\n",
        "pred=model.predict(x_test)\n",
        "print(\"평균절댓값백분율오차(MAPE):\", sum(abs(y_test-pred)/y_test)/len(x_test))\n",
        "\n",
        "plt.plot(hist.history['mae'])\n",
        "plt.plot(hist.history['val_mae'])\n",
        "plt.title('Model mae')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim([120,800])\n",
        "plt.legend(['Train','Validation'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "x_range=range(len(y_test))\n",
        "plt.plot(x_range,y_test[x_range],color='red')\n",
        "plt.plot(x_range,pred[x_range],color='blue')\n",
        "plt.legend(['True prices','Predicted prices'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "x_range=range(50,64)\n",
        "plt.plot(x_range,y_test[x_range],color='red')\n",
        "plt.plot(x_range,pred[x_range],color='blue')\n",
        "plt.legend(['True prices','Predicted prices'], loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GfUFrIzGvfzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import music21\n",
        "\n",
        "little_star=\"tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2\"\n",
        "music21.converter.parse(little_star).show('mid')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "note2num={'c':1,'d':2,'e':3,'f':4,'g':5,'a':6,'b':7}\n",
        "num2note={1:'c',2:'d',3:'e',4:'f',5:'g',6:'a',7:'b'}\n",
        "\n",
        "def abc2timeseries(s):\n",
        "    notes=s.split(' ')[2:]\n",
        "    seq=[]\n",
        "    for i in notes:\n",
        "        seq.append([note2num[i[0]],int(i[1])])\n",
        "    return seq\n",
        "\n",
        "def timeseries2abc(t):\n",
        "    s='tinynotation: 4/4' \n",
        "    for i in t:\n",
        "         s=s+' '+num2note[i[0]]+str(i[1]) \n",
        "    return s\n",
        "\n",
        "onehot=[[1,2],[2,2],[3,2],[4,2],[5,2],[6,2],[7,2],[1,4],[2,4],[3,4],[4,4],[5,4],[6,4],[7,4],[1,8],[2,8],[3,8],[4,8],[5,8],[6,8],[7,8]]\n",
        "\n",
        "def to_onehot(l):\n",
        "    t=[]\n",
        "    for i in range(len(l)):\n",
        "        a=np.zeros(len(onehot))\n",
        "        a[onehot.index(list(l[i]))]=1.0\n",
        "        t.append(a)\n",
        "    return np.array(t)\n",
        "\n",
        "def seq2dataset(seq,window,horizon):\n",
        "    X=[]; Y=[]\n",
        "    for i in range(len(seq)-(window+horizon)+1):\n",
        "        x=seq[i:(i+window)]\n",
        "        y=(seq[i+window+horizon-1])\n",
        "        X.append(x); Y.append(y)\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "w=8\n",
        "h=1\n",
        "\n",
        "seq=abc2timeseries(little_star)\n",
        "X,Y=seq2dataset(seq,w,h)\n",
        "print(X.shape,Y.shape)\n",
        "print(X[0],Y[0])\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Dense, LSTM\n",
        "import tensorflow as tf\n",
        "\n",
        "split = int(len(X)*1.0)\n",
        "x_train=X[0:split]; y_train=Y[0:split]\n",
        "y_train=to_onehot(y_train)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=128,activation='relu', input_shape=x_train[0].shape))\n",
        "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,epochs=200,batch_size=1,verbose=2)\n",
        "\n",
        "def arranging_music(model,first_measure,duration):\n",
        "    music=first_measure\n",
        "    for i in range(duration):\n",
        "        p=model.predict(np.float32(np.expand_dims(music[-w:],axis=0)))\n",
        "        music=np.append(music,[onehot[np.argmax(p)]],axis=0)\n",
        "    return timeseries2abc(music)\n",
        "\n",
        "new_song_arranging_music(model,x_train[0],50)\n",
        "\n",
        "print(new_song)\n",
        "music21.converter.parse(new_song).show('mid')"
      ],
      "metadata": {
        "id": "3TX978MF2lT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7qyuj-9yqd7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}